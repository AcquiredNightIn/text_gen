{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Embedding\n",
    "import pickle\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.preprocessing.sequence import pad_sequences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_file = \"../processed_data/20200224-202814\"\n",
    "\n",
    "with open(pickle_file, \"rb\") as f:\n",
    "    X, y, tokenizer, len_vocab = pickle.load(f) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 2, 50)             371700    \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 256)               314368    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 7434)              1910538   \n",
      "=================================================================\n",
      "Total params: 2,596,606\n",
      "Trainable params: 2,596,606\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "number_of_embeddings = 50\n",
    "LSTM_units = 256\n",
    "dropout = 0.1\n",
    "\n",
    "# define model\n",
    "model = Sequential()\n",
    "model.add(Embedding(len_vocab, number_of_embeddings, input_length=2))\n",
    "model.add(LSTM(LSTM_units))\n",
    "if dropout > 0:\n",
    "    model.add(Dropout(dropout))\n",
    "model.add(Dense(len_vocab, activation='softmax'))\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3622: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# compile network\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write callback section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"../best_callbacks/weights.best.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "early_stopping = EarlyStopping(monitor='val_acc', patience=5)\n",
    "callbacks_list = [checkpoint, early_stopping]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "124846\n"
     ]
    }
   ],
   "source": [
    "len_seq = X.shape[0]\n",
    "def build_model(X, y, v_split=0.2, number_of_epochs=10, verbose=1):\n",
    "    model.fit(X, y, validation_split=v_split, epochs=num_epochs, verbose=verbose)\n",
    "print(X.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Train on 83646 samples, validate on 41200 samples\n",
      "Epoch 1/10\n",
      "83646/83646 [==============================] - 86s 1ms/step - loss: 6.1405 - acc: 0.0682 - val_loss: 5.5985 - val_acc: 0.1216\n",
      "Epoch 2/10\n",
      "83646/83646 [==============================] - 88s 1ms/step - loss: 5.2034 - acc: 0.1524 - val_loss: 5.1914 - val_acc: 0.1661\n",
      "Epoch 3/10\n",
      "83646/83646 [==============================] - 83s 995us/step - loss: 4.7659 - acc: 0.1870 - val_loss: 5.0453 - val_acc: 0.1828\n",
      "Epoch 4/10\n",
      "83646/83646 [==============================] - 85s 1ms/step - loss: 4.4406 - acc: 0.2135 - val_loss: 4.9519 - val_acc: 0.1965\n",
      "Epoch 5/10\n",
      "83646/83646 [==============================] - 89s 1ms/step - loss: 4.1523 - acc: 0.2357 - val_loss: 4.9183 - val_acc: 0.2053\n",
      "Epoch 6/10\n",
      "83646/83646 [==============================] - 87s 1ms/step - loss: 3.8919 - acc: 0.2575 - val_loss: 4.8898 - val_acc: 0.2103\n",
      "Epoch 7/10\n",
      "83646/83646 [==============================] - 87s 1ms/step - loss: 3.6629 - acc: 0.2795 - val_loss: 4.8825 - val_acc: 0.2151\n",
      "Epoch 8/10\n",
      "83646/83646 [==============================] - 88s 1ms/step - loss: 3.4660 - acc: 0.3003 - val_loss: 4.8819 - val_acc: 0.2200\n",
      "Epoch 9/10\n",
      "83646/83646 [==============================] - 90s 1ms/step - loss: 3.2828 - acc: 0.3206 - val_loss: 4.8824 - val_acc: 0.2285\n",
      "Epoch 10/10\n",
      "83646/83646 [==============================] - 88s 1ms/step - loss: 3.1294 - acc: 0.3405 - val_loss: 4.8892 - val_acc: 0.2283\n"
     ]
    }
   ],
   "source": [
    "# fit network\n",
    "num_epochs = 10\n",
    "#batch_n = 50\n",
    "validation_split = 0.33\n",
    "\n",
    "build_model(X, y, v_split=validation_split, number_of_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function that will convert from the embedded numbers to text with a number of predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a sequence from a language model\n",
    "def generate_seq(model, tokenizer, max_length, seed_text, n_words):\n",
    "    in_text = seed_text\n",
    "    # generate a fixed number of words\n",
    "    for _ in range(n_words):\n",
    "        # encode the text as integer\n",
    "        encoded = tokenizer.texts_to_sequences([in_text])[0]\n",
    "        # pre-pad sequences to a fixed length\n",
    "        encoded = pad_sequences([encoded], maxlen=max_length, padding='pre')\n",
    "        # predict probabilities for each word\n",
    "        yhat = model.predict_classes(encoded, verbose=0)\n",
    "        # map predicted word index to word\n",
    "        out_word = ''\n",
    "        for word, index in tokenizer.word_index.items():\n",
    "            if index == yhat:\n",
    "                out_word = word\n",
    "                break\n",
    "        # append to input\n",
    "        in_text += ' ' + out_word\n",
    "    return in_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'there is the most of my life . . . . .'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_length = 3\n",
    "\n",
    "test = \"there is\"\n",
    "\n",
    "keras_embedder = tokenizer\n",
    "\n",
    "generate_seq(model, keras_embedder, max_length-1, test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My wife (30f) and my boyfriend (23m) of 4 years . i dont know what to do . . . . . . . . . . \n",
      "\n",
      "My husband (32m) feel like my boyfriend (23m) of 4 years . i dont know what to do . . . . . . . . . \n",
      "\n",
      "My friend (m26) and attempted suicide twice and i dont know what to do . . . . . . . . . . . . . \n",
      "\n",
      "My fiance (m29) is visibly a toxic relationship (18f)and i dont know what to do . . . . . . . . . . . . \n",
      "\n",
      "My (22M) from my girlfriend (f20) of 2 years and i dont know what to do . . . . . . . . . . . \n",
      "\n",
      "My girlfriend (20f) is always too late to go about a month , and i dont know what to do . . . . . . . \n",
      "\n",
      "My boyfriend (m29) is visibly a toxic relationship (18f)and i dont know what to do . . . . . . . . . . . . \n",
      "\n",
      "My partner (30m) of 7 years is mad at me . . . . . . . . . . . . . . . . . \n",
      "\n",
      "My (23F) from my girlfriend (f20) of 2 years and i dont know what to do . . . . . . . . . . . \n",
      "\n",
      "My spouse loved ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? \n",
      "\n"
     ]
    }
   ],
   "source": [
    "test1 = \"My wife\"\n",
    "test2 = \"My husband\"\n",
    "test3 = \"My friend\"\n",
    "test4 = \"My fiance\"\n",
    "test5 = \"My (22M)\"\n",
    "test6 = \"My girlfriend\"\n",
    "test7 = \"My boyfriend\"\n",
    "test8 = \"My partner\"\n",
    "test9 = \"My (23F)\"\n",
    "test10 = \"My spouse\"\n",
    "\n",
    "length = 25\n",
    "\n",
    "print(generate_seq(model, keras_embedder, max_length-1, test1, length),\"\\n\")\n",
    "print(generate_seq(model, keras_embedder, max_length-1, test2, length),\"\\n\")\n",
    "print(generate_seq(model, keras_embedder, max_length-1, test3, length),\"\\n\")\n",
    "print(generate_seq(model, keras_embedder, max_length-1, test4, length),\"\\n\")\n",
    "print(generate_seq(model, keras_embedder, max_length-1, test5, length),\"\\n\")\n",
    "print(generate_seq(model, keras_embedder, max_length-1, test6, length),\"\\n\")\n",
    "print(generate_seq(model, keras_embedder, max_length-1, test7, length),\"\\n\")\n",
    "print(generate_seq(model, keras_embedder, max_length-1, test8, length),\"\\n\")\n",
    "print(generate_seq(model, keras_embedder, max_length-1, test9, length),\"\\n\")\n",
    "print(generate_seq(model, keras_embedder, max_length-1, test10, length),\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
